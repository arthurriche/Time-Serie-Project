{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\i'\n",
      "/var/folders/v8/yj_gmdgd47l6hvz6s8ldkqfc0000gn/T/ipykernel_88727/3265394307.py:7: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "\n",
    "def construct_W(X, **kwargs):\n",
    "    \"\"\"\n",
    "    Construct the affinity matrix W through different ways\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    if kwargs is null, use the default parameter settings;\n",
    "    if kwargs is not null, construct the affinity matrix according to parameters in kwargs\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    kwargs: {dictionary}\n",
    "        parameters to construct different affinity matrix W:\n",
    "        y: {numpy array}, shape (n_samples, 1)\n",
    "            the true label information needed under the 'supervised' neighbor mode\n",
    "        metric: {string}\n",
    "            choices for different distance measures\n",
    "            'euclidean' - use euclidean distance\n",
    "            'cosine' - use cosine distance (default)\n",
    "        neighbor_mode: {string}\n",
    "            indicates how to construct the graph\n",
    "            'knn' - put an edge between two nodes if and only if they are among the\n",
    "                    k nearest neighbors of each other (default)\n",
    "            'supervised' - put an edge between two nodes if they belong to same class\n",
    "                    and they are among the k nearest neighbors of each other\n",
    "        weight_mode: {string}\n",
    "            indicates how to assign weights for each edge in the graph\n",
    "            'binary' - 0-1 weighting, every edge receives weight of 1 (default)\n",
    "            'heat_kernel' - if nodes i and j are connected, put weight W_ij = exp(-norm(x_i - x_j)/2t^2)\n",
    "                            this weight mode can only be used under 'euclidean' metric and you are required\n",
    "                            to provide the parameter t\n",
    "            'cosine' - if nodes i and j are connected, put weight cosine(x_i,x_j).\n",
    "                        this weight mode can only be used under 'cosine' metric\n",
    "        k: {int}\n",
    "            choices for the number of neighbors (default k = 5)\n",
    "        t: {float}\n",
    "            parameter for the 'heat_kernel' weight_mode\n",
    "        fisher_score: {boolean}\n",
    "            indicates whether to build the affinity matrix in a fisher score way, in which W_ij = 1/n_l if yi = yj = l;\n",
    "            otherwise W_ij = 0 (default fisher_score = false)\n",
    "        reliefF: {boolean}\n",
    "            indicates whether to build the affinity matrix in a reliefF way, NH(x) and NM(x,y) denotes a set of\n",
    "            k nearest points to x with the same class as x, and a different class (the class y), respectively.\n",
    "            W_ij = 1 if i = j; W_ij = 1/k if x_j \\in NH(x_i); W_ij = -1/(c-1)k if x_j \\in NM(x_i, y) (default reliefF = false)\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    W: {sparse matrix}, shape (n_samples, n_samples)\n",
    "        output affinity matrix W\n",
    "    \"\"\"\n",
    "\n",
    "    # default metric is 'cosine'\n",
    "    if 'metric' not in kwargs.keys():\n",
    "        kwargs['metric'] = 'cosine'\n",
    "\n",
    "    # default neighbor mode is 'knn' and default neighbor size is 5\n",
    "    if 'neighbor_mode' not in kwargs.keys():\n",
    "        kwargs['neighbor_mode'] = 'knn'\n",
    "    if kwargs['neighbor_mode'] == 'knn' and 'k' not in kwargs.keys():\n",
    "        kwargs['k'] = 5\n",
    "    if kwargs['neighbor_mode'] == 'supervised' and 'k' not in kwargs.keys():\n",
    "        kwargs['k'] = 5\n",
    "    if kwargs['neighbor_mode'] == 'supervised' and 'y' not in kwargs.keys():\n",
    "        print ('Warning: label is required in the supervised neighborMode!!!')\n",
    "        exit(0)\n",
    "\n",
    "    # default weight mode is 'binary', default t in heat kernel mode is 1\n",
    "    if 'weight_mode' not in kwargs.keys():\n",
    "        kwargs['weight_mode'] = 'binary'\n",
    "    if kwargs['weight_mode'] == 'heat_kernel':\n",
    "        if kwargs['metric'] != 'euclidean':\n",
    "            kwargs['metric'] = 'euclidean'\n",
    "        if 't' not in kwargs.keys():\n",
    "            kwargs['t'] = 1\n",
    "    elif kwargs['weight_mode'] == 'cosine':\n",
    "        if kwargs['metric'] != 'cosine':\n",
    "            kwargs['metric'] = 'cosine'\n",
    "\n",
    "    # default fisher_score and reliefF mode are 'false'\n",
    "    if 'fisher_score' not in kwargs.keys():\n",
    "        kwargs['fisher_score'] = False\n",
    "    if 'reliefF' not in kwargs.keys():\n",
    "        kwargs['reliefF'] = False\n",
    "\n",
    "    n_samples, n_features = np.shape(X)\n",
    "\n",
    "    # choose 'knn' neighbor mode\n",
    "    if kwargs['neighbor_mode'] == 'knn':\n",
    "        k = kwargs['k']\n",
    "        if kwargs['weight_mode'] == 'binary':\n",
    "            if kwargs['metric'] == 'euclidean':\n",
    "                # compute pairwise euclidean distances\n",
    "                D = pairwise_distances(X)\n",
    "                D **= 2\n",
    "                # sort the distance matrix D in ascending order\n",
    "                dump = np.sort(D, axis=1)\n",
    "                idx = np.argsort(D, axis=1)\n",
    "                # choose the k-nearest neighbors for each instance\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "                G[:, 1] = np.ravel(idx_new, order='F')\n",
    "                G[:, 2] = 1\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "            elif kwargs['metric'] == 'cosine':\n",
    "                # normalize the data first\n",
    "                X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "                for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "                # compute pairwise cosine distances\n",
    "                D_cosine = np.dot(X, np.transpose(X))\n",
    "                # sort the distance matrix D in descending order\n",
    "                dump = np.sort(-D_cosine, axis=1)\n",
    "                idx = np.argsort(-D_cosine, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "                G[:, 1] = np.ravel(idx_new, order='F')\n",
    "                G[:, 2] = 1\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'heat_kernel':\n",
    "            t = kwargs['t']\n",
    "            # compute pairwise euclidean distances\n",
    "            D = pairwise_distances(X)\n",
    "            D **= 2\n",
    "            # sort the distance matrix D in ascending order\n",
    "            dump = np.sort(D, axis=1)\n",
    "            idx = np.argsort(D, axis=1)\n",
    "            idx_new = idx[:, 0:k+1]\n",
    "            dump_new = dump[:, 0:k+1]\n",
    "            # compute the pairwise heat kernel distances\n",
    "            dump_heat_kernel = np.exp(-dump_new/(2*t*t))\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "            G[:, 1] = np.ravel(idx_new, order='F')\n",
    "            G[:, 2] = np.ravel(dump_heat_kernel, order='F')\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'cosine':\n",
    "            # normalize the data first\n",
    "            X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "            for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "            # compute pairwise cosine distances\n",
    "            D_cosine = np.dot(X, np.transpose(X))\n",
    "            # sort the distance matrix D in ascending order\n",
    "            dump = np.sort(-D_cosine, axis=1)\n",
    "            idx = np.argsort(-D_cosine, axis=1)\n",
    "            idx_new = idx[:, 0:k+1]\n",
    "            dump_new = -dump[:, 0:k+1]\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "            G[:, 1] = np.ravel(idx_new, order='F')\n",
    "            G[:, 2] = np.ravel(dump_new, order='F')\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "\n",
    "    # choose supervised neighborMode\n",
    "    elif kwargs['neighbor_mode'] == 'supervised':\n",
    "        k = kwargs['k']\n",
    "        # get true labels and the number of classes\n",
    "        y = kwargs['y']\n",
    "        label = np.unique(y)\n",
    "        n_classes = np.unique(y).size\n",
    "        # construct the weight matrix W in a fisherScore way, W_ij = 1/n_l if yi = yj = l, otherwise W_ij = 0\n",
    "        if kwargs['fisher_score'] is True:\n",
    "            W = lil_matrix((n_samples, n_samples))\n",
    "            for i in range(n_classes):\n",
    "                class_idx = (y == label[i])\n",
    "                class_idx_all = (class_idx[:, np.newaxis] & class_idx[np.newaxis, :])\n",
    "                W[class_idx_all] = 1.0/np.sum(np.sum(class_idx))\n",
    "            return W\n",
    "\n",
    "        # construct the weight matrix W in a reliefF way, NH(x) and NM(x,y) denotes a set of k nearest\n",
    "        # points to x with the same class as x, a different class (the class y), respectively. W_ij = 1 if i = j;\n",
    "        # W_ij = 1/k if x_j \\in NH(x_i); W_ij = -1/(c-1)k if x_j \\in NM(x_i, y)\n",
    "        if kwargs['reliefF'] is True:\n",
    "            # when xj in NH(xi)\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                D = pairwise_distances(X[class_idx, :])\n",
    "                D **= 2\n",
    "                idx = np.argsort(D, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                n_smp_class = (class_idx[idx_new[:]]).size\n",
    "                if len(class_idx) <= k:\n",
    "                    k = len(class_idx) - 1\n",
    "                G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                G[id_now:n_smp_class+id_now, 2] = 1.0/k\n",
    "                id_now += n_smp_class\n",
    "            W1 = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            # when i = j, W_ij = 1\n",
    "            for i in range(n_samples):\n",
    "                W1[i, i] = 1\n",
    "            # when x_j in NM(x_i, y)\n",
    "            G = np.zeros((n_samples*k*(n_classes - 1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx1 = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                X1 = X[class_idx1, :]\n",
    "                for j in range(n_classes):\n",
    "                    if label[j] != label[i]:\n",
    "                        class_idx2 = np.column_stack(np.where(y == label[j]))[:, 0]\n",
    "                        X2 = X[class_idx2, :]\n",
    "                        D = pairwise_distances(X1, X2)\n",
    "                        idx = np.argsort(D, axis=1)\n",
    "                        idx_new = idx[:, 0:k]\n",
    "                        n_smp_class = len(class_idx1)*k\n",
    "                        G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx1, (k, 1)).reshape(-1)\n",
    "                        G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx2[idx_new[:]], order='F')\n",
    "                        G[id_now:n_smp_class+id_now, 2] = -1.0/((n_classes-1)*k)\n",
    "                        id_now += n_smp_class\n",
    "            W2 = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W2) > W2\n",
    "            W2 = W2 - W2.multiply(bigger) + np.transpose(W2).multiply(bigger)\n",
    "            W = W1 + W2\n",
    "            return W\n",
    "\n",
    "        if kwargs['weight_mode'] == 'binary':\n",
    "            if kwargs['metric'] == 'euclidean':\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                id_now = 0\n",
    "                for i in range(n_classes):\n",
    "                    class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                    # compute pairwise euclidean distances for instances in class i\n",
    "                    D = pairwise_distances(X[class_idx, :])\n",
    "                    D **= 2\n",
    "                    # sort the distance matrix D in ascending order for instances in class i\n",
    "                    idx = np.argsort(D, axis=1)\n",
    "                    idx_new = idx[:, 0:k+1]\n",
    "                    n_smp_class = len(class_idx)*(k+1)\n",
    "                    G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                    G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                    G[id_now:n_smp_class+id_now, 2] = 1\n",
    "                    id_now += n_smp_class\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "            if kwargs['metric'] == 'cosine':\n",
    "                # normalize the data first\n",
    "                X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "                for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                id_now = 0\n",
    "                for i in range(n_classes):\n",
    "                    class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                    # compute pairwise cosine distances for instances in class i\n",
    "                    D_cosine = np.dot(X[class_idx, :], np.transpose(X[class_idx, :]))\n",
    "                    # sort the distance matrix D in descending order for instances in class i\n",
    "                    idx = np.argsort(-D_cosine, axis=1)\n",
    "                    idx_new = idx[:, 0:k+1]\n",
    "                    n_smp_class = len(class_idx)*(k+1)\n",
    "                    G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                    G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                    G[id_now:n_smp_class+id_now, 2] = 1\n",
    "                    id_now += n_smp_class\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'heat_kernel':\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                # compute pairwise cosine distances for instances in class i\n",
    "                D = pairwise_distances(X[class_idx, :])\n",
    "                D **= 2\n",
    "                # sort the distance matrix D in ascending order for instances in class i\n",
    "                dump = np.sort(D, axis=1)\n",
    "                idx = np.argsort(D, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                dump_new = dump[:, 0:k+1]\n",
    "                t = kwargs['t']\n",
    "                # compute pairwise heat kernel distances for instances in class i\n",
    "                dump_heat_kernel = np.exp(-dump_new/(2*t*t))\n",
    "                n_smp_class = len(class_idx)*(k+1)\n",
    "                G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                G[id_now:n_smp_class+id_now, 2] = np.ravel(dump_heat_kernel, order='F')\n",
    "                id_now += n_smp_class\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'cosine':\n",
    "            # normalize the data first\n",
    "            X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "            for i in range(n_samples):\n",
    "                X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                # compute pairwise cosine distances for instances in class i\n",
    "                D_cosine = np.dot(X[class_idx, :], np.transpose(X[class_idx, :]))\n",
    "                # sort the distance matrix D in descending order for instances in class i\n",
    "                dump = np.sort(-D_cosine, axis=1)\n",
    "                idx = np.argsort(-D_cosine, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                dump_new = -dump[:, 0:k+1]\n",
    "                n_smp_class = len(class_idx)*(k+1)\n",
    "                G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                G[id_now:n_smp_class+id_now, 2] = np.ravel(dump_new, order='F')\n",
    "                id_now += n_smp_class\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.sparse import diags\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the train and test datasets\n",
    "data_train = pd.read_csv('/Users/ludoviclepic/.cache/kagglehub/datasets/uciml/human-activity-recognition-with-smartphones/versions/2/train.csv')\n",
    "data_test = pd.read_csv('/Users/ludoviclepic/.cache/kagglehub/datasets/uciml/human-activity-recognition-with-smartphones/versions/2/test.csv')\n",
    "\n",
    "# Split features and target for both train and test\n",
    "X_train = data_train.iloc[:, :-1]\n",
    "y_train = data_train.iloc[:, -1]\n",
    "X_test = data_test.iloc[:, :-1]\n",
    "y_test = data_test.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using All Features: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Train on all features\n",
    "classifier_all = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "classifier_all.fit(X_scaled, y_encoded)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred_all = classifier_all.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_all_features = accuracy_score(y_test_encoded, y_pred_all)\n",
    "print(f\"Accuracy using all {X_test.shape} Features: {accuracy_all_features:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_score(X, **kwargs):\n",
    "    \"\"\"\n",
    "    This function implements the laplacian score feature selection, steps are as follows:\n",
    "    1. Construct the affinity matrix W if it is not specified\n",
    "    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n",
    "    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n",
    "    4. Laplacian score for the r-th feature is score = (fr_hat'*L*fr_hat)/(fr_hat'*D*fr_hat)\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    kwargs: {dictionary}\n",
    "        W: {sparse matrix}, shape (n_samples, n_samples)\n",
    "            input affinity matrix\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    score: {numpy array}, shape (n_features,)\n",
    "        laplacian score for each feature\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
    "    \"\"\"\n",
    "\n",
    "    # if 'W' is not specified, use the default W\n",
    "    if 'W' not in kwargs.keys():\n",
    "        W = construct_W(X)\n",
    "    # construct the affinity matrix W\n",
    "    W = kwargs['W']\n",
    "    # build the diagonal D matrix from affinity matrix W\n",
    "    D = np.array(W.sum(axis=1))\n",
    "    L = W\n",
    "    tmp = np.dot(np.transpose(D), X)\n",
    "    D = diags(np.transpose(D), [0])\n",
    "    Xt = np.transpose(X)\n",
    "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
    "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
    "    # compute the numerator of Lr\n",
    "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # compute the denominator of Lr\n",
    "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # avoid the denominator of Lr to be 0\n",
    "    D_prime[D_prime < 1e-12] = 10000\n",
    "\n",
    "    # compute laplacian score for all features\n",
    "    score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
    "    return np.transpose(score)\n",
    "\n",
    "\n",
    "def feature_ranking(score):\n",
    "    \"\"\"\n",
    "    Rank features in ascending order according to their laplacian scores, the smaller the laplacian score is, the more\n",
    "    important the feature is\n",
    "    \"\"\"\n",
    "    idx = np.argsort(score, 0)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with top 562 features: 0.64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of features: 483\n",
      "Best accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "W = construct_W(X_scaled)  # Affinity matrix\n",
    "laplacian_scores = lap_score(X_scaled, W=W)\n",
    "ranked_features = feature_ranking(laplacian_scores)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_num_features = 0\n",
    "best_model = None\n",
    "\n",
    "num_features_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for num_features in range(1, len(ranked_features) + 1, 25):\n",
    "    top_laplacian_features = ranked_features[:num_features]\n",
    "    \n",
    "    # Subset the train and test data with top Laplacian features\n",
    "    X_train_laplacian = X_scaled[:, top_laplacian_features]\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_laplacian = X_test_scaled[:, top_laplacian_features]\n",
    "    \n",
    "    # Train and evaluate the classifier\n",
    "    classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "    classifier.fit(X_train_laplacian, y_encoded)\n",
    "    y_pred_laplacian = classifier.predict(X_test_laplacian)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    accuracy_laplacian = accuracy_score(y_test_encoded, y_pred_laplacian)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Accuracy with top {num_features} features: {accuracy_laplacian:.2f}\")\n",
    "\n",
    "    num_features_list.append(num_features)\n",
    "    accuracy_list.append(accuracy_laplacian)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Number of Features')\n",
    "    plt.grid(True)\n",
    "    plt.plot(num_features_list, accuracy_list, marker='o')\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    # Track the best model\n",
    "    if accuracy_laplacian > best_accuracy:\n",
    "        best_accuracy = accuracy_laplacian\n",
    "        best_num_features = num_features\n",
    "        best_model = classifier\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Best number of features: {best_num_features}\")\n",
    "print(f\"Best accuracy: {best_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Information Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_score(X, y):\n",
    "    \"\"\"\n",
    "    This function implements the fisher score feature selection, steps are as follows:\n",
    "    1. Construct the affinity matrix W in fisher score way\n",
    "    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n",
    "    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n",
    "    4. Fisher score for the r-th feature is score = (fr_hat'*D*fr_hat)/(fr_hat'*L*fr_hat)-1\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    y: {numpy array}, shape (n_samples,)\n",
    "        input class labels\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    score: {numpy array}, shape (n_features,)\n",
    "        fisher score for each feature\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
    "    Duda, Richard et al. \"Pattern classification.\" John Wiley & Sons, 2012.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct weight matrix W in a fisherScore way\n",
    "    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n",
    "    W = construct_W(X, **kwargs)\n",
    "\n",
    "    # build the diagonal D matrix from affinity matrix W\n",
    "    D = np.array(W.sum(axis=1))\n",
    "    L = W\n",
    "    tmp = np.dot(np.transpose(D), X)\n",
    "    D = diags(np.transpose(D), [0])\n",
    "    Xt = np.transpose(X)\n",
    "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
    "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
    "    # compute the numerator of Lr\n",
    "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # compute the denominator of Lr\n",
    "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # avoid the denominator of Lr to be 0\n",
    "    D_prime[D_prime < 1e-12] = 10000\n",
    "    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
    "\n",
    "    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n",
    "    score = 1.0/lap_score - 1\n",
    "    return np.transpose(score)\n",
    "\n",
    "\n",
    "def feature_ranking(score):\n",
    "    \"\"\"\n",
    "    Rank features in descending order according to fisher score, the larger the fisher score, the more important the\n",
    "    feature is\n",
    "    \"\"\"\n",
    "    idx = np.argsort(score, 0)\n",
    "    return idx[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Fisher Features: [280  95 231 226 359  15 366 200 218 213]\n",
      "Accuracy using Fisher-Selected Features: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Fisher Score Pipeline\n",
    "# Compute Fisher Scores for the dataset\n",
    "fisher_scores = fisher_score(X_scaled, y_encoded)\n",
    "ranked_features_fisher = feature_ranking(fisher_scores)\n",
    "\n",
    "# Select top 10 ranked features\n",
    "top_fisher_features = ranked_features_fisher[:10]\n",
    "print(\"Top Fisher Features:\", top_fisher_features)\n",
    "\n",
    "# Subset the train and test data with top Fisher features\n",
    "X_train_fisher = X_scaled[:, top_fisher_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_fisher = X_test_scaled[:, top_fisher_features]\n",
    "\n",
    "# Train and evaluate the classifier\n",
    "classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "classifier.fit(X_train_fisher, y_encoded)\n",
    "y_pred_fisher = classifier.predict(X_test_fisher)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_fisher = accuracy_score(y_test_encoded, y_pred_fisher)\n",
    "print(f\"Accuracy using Fisher-Selected Features: {accuracy_fisher:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Learning Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOSCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the GOSCAR optimization function\n",
    "def goscar_loss(beta, X, y, lambda1, lambda2):\n",
    "    \"\"\"\n",
    "    Loss function for GOSCAR regularization.\n",
    "\n",
    "    Args:\n",
    "        beta (array): Coefficients to optimize.\n",
    "        X (array): Feature matrix.\n",
    "        y (array): Target variable.\n",
    "        lambda1 (float): Regularization parameter for L1 norm.\n",
    "        lambda2 (float): Regularization parameter for grouping effects.\n",
    "\n",
    "    Returns:\n",
    "        float: Value of the GOSCAR loss function.\n",
    "    \"\"\"\n",
    "    residual = y - np.dot(X, beta)\n",
    "    l1_norm = np.sum(np.abs(beta))\n",
    "    group_penalty = np.sum(\n",
    "        [max(abs(beta[i]), abs(beta[j])) for i in range(len(beta)) for j in range(i + 1, len(beta))]\n",
    "    )\n",
    "    return np.sum(residual**2) / 2 + lambda1 * l1_norm + lambda2 * group_penalty\n",
    "\n",
    "# Solve the GOSCAR optimization problem\n",
    "def goscar_feature_selection(X, y, lambda1=0.1, lambda2=0.1):\n",
    "    \"\"\"\n",
    "    Perform GOSCAR feature selection.\n",
    "\n",
    "    Args:\n",
    "        X (array): Feature matrix.\n",
    "        y (array): Target variable.\n",
    "        lambda1 (float): Regularization parameter for L1 norm.\n",
    "        lambda2 (float): Regularization parameter for grouping effects.\n",
    "\n",
    "    Returns:\n",
    "        array: Coefficients of the GOSCAR optimization problem.\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    initial_beta = np.zeros(n_features)\n",
    "    result = minimize(\n",
    "        goscar_loss,\n",
    "        initial_beta,\n",
    "        args=(X, y, lambda1, lambda2),\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"disp\": True},\n",
    "    )\n",
    "    return result.x  # Optimized coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          562     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.02085D+04    |proj g|=  1.04484D+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    1    f=  2.32938D+04    |proj g|=  3.78393D+03\n",
      "\n",
      "At iterate    2    f=  2.20330D+04    |proj g|=  2.77157D+03\n",
      "\n",
      "At iterate    3    f=  2.11274D+04    |proj g|=  1.23115D+03\n",
      "\n",
      "At iterate    4    f=  2.08915D+04    |proj g|=  5.74255D+02\n",
      "\n",
      "At iterate    5    f=  2.07573D+04    |proj g|=  3.96356D+02\n",
      "\n",
      "At iterate    6    f=  2.06548D+04    |proj g|=  3.50782D+02\n",
      "\n",
      "At iterate    7    f=  2.06015D+04    |proj g|=  2.46855D+02\n",
      "\n",
      "At iterate    8    f=  2.05738D+04    |proj g|=  2.25579D+02\n",
      "\n",
      "At iterate    9    f=  2.05544D+04    |proj g|=  1.68155D+02\n",
      "\n",
      "At iterate   10    f=  2.05421D+04    |proj g|=  1.26616D+02\n",
      "\n",
      "At iterate   11    f=  2.05338D+04    |proj g|=  8.16905D+01\n",
      "\n",
      "At iterate   12    f=  2.05301D+04    |proj g|=  7.16325D+01\n",
      "\n",
      "At iterate   13    f=  2.05298D+04    |proj g|=  1.13729D+02\n",
      "\n",
      "At iterate   14    f=  2.05274D+04    |proj g|=  7.34559D+01\n",
      "\n",
      "At iterate   15    f=  2.05250D+04    |proj g|=  6.87491D+01\n",
      "\n",
      "At iterate   16    f=  2.05209D+04    |proj g|=  6.02871D+01\n",
      "\n",
      "At iterate   17    f=  2.05193D+04    |proj g|=  9.05417D+01\n",
      "\n",
      "At iterate   18    f=  2.05174D+04    |proj g|=  5.52067D+01\n",
      "\n",
      "At iterate   19    f=  2.05150D+04    |proj g|=  5.16218D+01\n",
      "\n",
      "At iterate   20    f=  2.05134D+04    |proj g|=  5.73313D+01\n",
      "\n",
      "At iterate   21    f=  2.05105D+04    |proj g|=  5.85140D+01\n",
      "\n",
      "At iterate   22    f=  2.05088D+04    |proj g|=  6.49921D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  562     22     27      1     0     0   6.499D+01   2.051D+04\n",
      "  F =   20508.799875311841     \n",
      "\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT        \n",
      "Selected Features (GOSCAR): [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450\n",
      " 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468\n",
      " 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486\n",
      " 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504\n",
      " 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522\n",
      " 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540\n",
      " 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558\n",
      " 559 560 561]\n",
      "Accuracy using GOSCAR-Selected Features: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Solve GOSCAR\n",
    "goscar_coefficients = goscar_feature_selection(X_scaled, y_encoded, lambda1=0.1, lambda2=0.1)\n",
    "\n",
    "# Select top features (non-zero coefficients)\n",
    "selected_features = np.where(np.abs(goscar_coefficients) > 1e-5)[0]\n",
    "print(\"Selected Features (GOSCAR):\", selected_features)\n",
    "\n",
    "# Subset the train and test data with GOSCAR-selected features\n",
    "X_train_goscar = X_scaled[:, selected_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_goscar = X_test_scaled[:, selected_features]\n",
    "\n",
    "# Train and evaluate the classifier\n",
    "classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "classifier.fit(X_train_goscar, y_encoded)\n",
    "y_pred_goscar = classifier.predict(X_test_goscar)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_goscar = accuracy_score(y_test_encoded, y_pred_goscar)\n",
    "print(f\"Accuracy using GOSCAR-Selected Features: {accuracy_goscar:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_variance_feature_selection(X, threshold):\n",
    "    variances = np.var(X, axis=0)\n",
    "    selected_features = np.where(variances > threshold)[0]\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "    return X_selected, selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Low Variance): [  3   4   7   9  15  22  40  49  52  56  77  78  79  87 102 103 104 142\n",
      " 144 182 183 184 200 203 205 208 213 216 218 221 234 247 260 266 268 269\n",
      " 271 272 280 287 288 289 350 366 367 368 445 446 447 502 507 510 523 536\n",
      " 549 555 556 557 558 561]\n",
      "Accuracy using Low Variance-Selected Features: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Apply low variance feature selection before scaling\n",
    "threshold = 0.2  # Example threshold\n",
    "X_train_low_variance, selected_features = low_variance_feature_selection(X_train, threshold)\n",
    "\n",
    "print(\"Selected Features (Low Variance):\", selected_features)\n",
    "\n",
    "# Standardize the selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_low_variance)\n",
    "\n",
    "# Subset and scale the test data with the same selected features\n",
    "X_test_low_variance = X_test.iloc[:, selected_features]\n",
    "X_test_scaled = scaler.transform(X_test_low_variance)\n",
    "\n",
    "# Train and evaluate the classifier\n",
    "classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "classifier.fit(X_train_scaled, y_encoded)\n",
    "y_pred_low_variance = classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_low_variance = accuracy_score(y_test_encoded, y_pred_low_variance)\n",
    "print(f\"Accuracy using Low Variance-Selected Features: {accuracy_low_variance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 555 is out of bounds for axis 1 with size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracies\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Laplacian features\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m laplacian_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_laplacian_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Fisher features\u001b[39;00m\n\u001b[1;32m     20\u001b[0m fisher_accuracies \u001b[38;5;241m=\u001b[39m evaluate_features(X_scaled, y_encoded, X_test_scaled, y_test_encoded, top_fisher_features, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 9\u001b[0m, in \u001b[0;36mevaluate_features\u001b[0;34m(X_train, y_train, X_test, y_test, ranked_features, max_features)\u001b[0m\n\u001b[1;32m      7\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m ranked_features[:k]\n\u001b[1;32m      8\u001b[0m X_train_subset \u001b[38;5;241m=\u001b[39m X_train[:, selected_features]\n\u001b[0;32m----> 9\u001b[0m X_test_subset \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X_train_subset, y_train)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 555 is out of bounds for axis 1 with size 60"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_features(X_train, y_train, X_test, y_test, ranked_features, max_features):\n",
    "    accuracies = []\n",
    "    for k in range(1, max_features + 1):\n",
    "        selected_features = ranked_features[:k]\n",
    "        X_train_subset = X_train[:, selected_features]\n",
    "        X_test_subset = X_test[:, selected_features]\n",
    "        classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "        classifier.fit(X_train_subset, y_train)\n",
    "        y_pred = classifier.predict(X_test_subset)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    return accuracies\n",
    "\n",
    "# Laplacian features\n",
    "laplacian_accuracies = evaluate_features(X_scaled, y_encoded, X_test_scaled, y_test_encoded, top_laplacian_features, 10)\n",
    "\n",
    "# Fisher features\n",
    "fisher_accuracies = evaluate_features(X_scaled, y_encoded, X_test_scaled, y_test_encoded, top_fisher_features, 10)\n",
    "\n",
    "# Plot results\n",
    "plt.plot(range(1, 11), laplacian_accuracies, label=\"Laplacian\")\n",
    "plt.plot(range(1, 11), fisher_accuracies, label=\"Fisher\")\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy vs. Number of Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
